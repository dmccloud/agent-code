{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain_community.agent_toolkits.github.toolkit import GitHubToolkit\n",
    "from langchain_community.utilities.github import GitHubAPIWrapper\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your environment variables using os.environ\n",
    "os.environ[\"GITHUB_APP_ID\"]\n",
    "os.environ[\"GITHUB_APP_PRIVATE_KEY\"] \n",
    "os.environ[\"GITHUB_REPOSITORY\"] \n",
    "os.environ[\"GITHUB_BRANCH\"] \n",
    "os.environ[\"GITHUB_BASE_BRANCH\"] \n",
    "os.environ[\"OPENAI_API_KEY\"] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4-1106-preview\")\n",
    "github = GitHubAPIWrapper()\n",
    "toolkit = GitHubToolkit.from_github_api_wrapper(github)\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "# STRUCTURED_CHAT includes args_schema for each tool, helps tool args parsing errors.\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")\n",
    "print(\"Available tools:\")\n",
    "for tool in tools:\n",
    "    print(\"\\t\" + tool.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\n",
    "    \"You have the software engineering capabilities of a Google Principle engineer. You are tasked with completing issues on a github repository. Please look at the existing issues and complete them.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh_issue_prompt_template = \"\"\"Please implement these changes by creating or editing the necessary files. \n",
    "\n",
    "1. First use read_file to read any files in the repo that seem relevant. \n",
    "2. Then, when you're ready, start implementing changes by creating and updating files. Implement any and all remaining code to make the project work as the commenter intended. \n",
    "2. The last step is to create a PR with a clear and concise title and description, list any concerns or final changes necessary in the PR body.\n",
    "3. After opening the PR, comment on the original issue and mention the new PR your just opened, you must comment \"I opened a PR for you to review here #<PR_NUMBER>\" (it'll be something like #30). That hashtag syntax will automatically link to the PR, as necessary. Thanks.\n",
    "4. If you feel the PR is satisfactory for completing your assignment, create a review request for the original user that opened the issue. Use their username to tag them.\n",
    "\n",
    "Feel free to ask for help or leave a comment on the Issue or PR if you're stuck.\n",
    "\n",
    "Here's your latest assignment: {issue_description}\"\"\"\n",
    "\n",
    "print(gh_issue_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_issue(issue):\n",
    "    title = f\"Title: {issue.get('title')}.\"\n",
    "    opened_by = f\"Opened by user: {issue.get('opened_by')}\"\n",
    "    body = f\"Body: {issue.get('body')}\"\n",
    "    comments = issue.get(\"comments\")  # often too long\n",
    "    return \"\\n\".join([title, opened_by, body])\n",
    "\n",
    "\n",
    "issue = github.get_issue(27)  # task to implement a RNA-seq pipeline (bioinformatics)\n",
    "final_gh_issue_prompt = gh_issue_prompt_template.format(\n",
    "    issue_description=format_issue(issue)\n",
    ")\n",
    "print(final_gh_issue_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory.summary_buffer import ConversationSummaryBufferMemory\n",
    "from langchain_core.prompts.chat import MessagesPlaceholder\n",
    "\n",
    "summarizer_llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")  # type: ignore\n",
    "chat_history = MessagesPlaceholder(variable_name=\"chat_history\")\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    llm=summarizer_llm,\n",
    "    max_token_limit=16_000,\n",
    ")\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,  # or pass a function that accepts the error and returns a string\n",
    "    max_iterations=30,\n",
    "    max_execution_time=None,\n",
    "    early_stopping_method=\"generate\",\n",
    "    memory=memory,\n",
    "    # trim_intermediate_steps=fancier_trim_intermediate_steps,\n",
    "    agent_kwargs={\n",
    "        \"memory_prompts\": [chat_history],\n",
    "        \"input_variables\": [\"input\", \"agent_scratchpad\", \"chat_history\"],\n",
    "        \"prefix\": final_gh_issue_prompt,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(final_gh_issue_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
